{
  "task_id": "BigCodeBench/177",
  "instruct_prompt": "Extracts articles whose titles contain specific case-insensitive keywords (\"like\" or \"what\") from a DataFrame and analyzes the frequency of each word in the content of these articles, excluding punctuation.\nThe function should raise the exception for: ValueError: If the DataFrame is empty or does not contain the necessary columns 'Title' and 'Content'.\nThe function should output with:\n    dict: A dictionary with keys as words and values as their corresponding frequency, excluding any punctuation marks.\nYou should write self-contained code starting with:\n```\nimport re\nimport nltk\nfrom string import punctuation\ndef task_func(df):\n```",
  "llm_response": "import re\nimport nltk\nfrom string import punctuation\ndef task_func(df):\n    \"\"\"\n    Extracts articles with titles containing 'like' or 'what' (case-insensitive),\n    analyzes word frequency in their content (excluding punctuation), and returns\n    a dictionary of word frequencies.\n\n    Args:\n        df: pandas DataFrame containing 'Title' and 'Content' columns\n\n    Returns:\n        dict: Dictionary of word frequencies\n\n    Raises:\n        ValueError: If DataFrame is empty or missing required columns\n    \"\"\"\n    # Check for empty DataFrame\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n\n    # Check for required columns\n    required_columns = {'Title', 'Content'}\n    if not required_columns.issubset(df.columns):\n        raise ValueError(\"DataFrame must contain 'Title' and 'Content' columns\")\n\n    # Filter articles with titles containing 'like' or 'what' (case-insensitive)\n    filtered_df = df[\n        df['Title'].str.contains('like|what', case=False, regex=True)\n    ]\n\n    # If no matching articles, return empty dict\n    if filtered_df.empty:\n        return {}\n\n    # Combine all content into a single string\n    all_content = ' '.join(filtered_df['Content'].astype(str))\n\n    # Remove punctuation and convert to lowercase\n    translator = str.maketrans('', '', punctuation)\n    cleaned_text = all_content.translate(translator).lower()\n\n    # Tokenize the text\n    words = nltk.word_tokenize(cleaned_text)\n\n    # Count word frequencies\n    word_freq = {}\n    for word in words:\n        if word:  # Skip empty strings\n            word_freq[word] = word_freq.get(word, 0) + 1\n\n    return word_freq",
  "model": "mistral-3.2-24b"
}