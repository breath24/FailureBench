{
  "task_id": "BigCodeBench/723",
  "instruct_prompt": "Scrape data from a given URL and save the scraped data to a CSV file.\nThe function should output with:\n    CSV_FILE_PATH (str): The path of the CSV file where the scraped data is saved.\nYou should write self-contained code starting with:\n```\nimport urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\n# Constants\nCSV_FILE_PATH = 'scraped_data.csv'\ndef task_func(url):\n```",
  "llm_response": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\nCSV_FILE_PATH = 'scraped_data.csv'\ndef task_func(url):\n    \"\"\"\n    Scrapes data from the given URL and saves it to a CSV file.\n\n    Args:\n        url (str): The URL to scrape data from.\n\n    Returns:\n        str: The path of the CSV file where the scraped data is saved.\n    \"\"\"\n    try:\n        # Fetch the webpage content\n        with urllib.request.urlopen(url) as response:\n            html_content = response.read()\n\n        # Parse the HTML content\n        soup = BeautifulSoup(html_content, 'html.parser')\n\n        # Find all relevant data elements - this example extracts all links\n        # You can modify this part to extract the specific data you need\n        data = []\n        for link in soup.find_all('a'):\n            data.append({\n                'text': link.get_text(strip=True),\n                'href': link.get('href')\n            })\n\n        # Write data to CSV file\n        with open(CSV_FILE_PATH, 'w', newline='', encoding='utf-8') as csvfile:\n            fieldnames = ['text', 'href']\n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n            writer.writeheader()\n            for item in data:\n                writer.writerow(item)\n\n        return CSV_FILE_PATH\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None",
  "model": "mistral-3.2-24b"
}