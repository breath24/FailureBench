{
  "task_id": "3764",
  "task_description": "You are given a 2D integer matrix grid of size n x m, an integer array limits of length n, and an integer k. The task is to find the maximum sum of at most k elements from the matrix grid such that:\n\n\nThe number of elements taken from the i^th row of grid does not exceed limits[i].\n\n\nReturn the maximum sum.\n \nExample 1:\n\nInput: grid = [[1,2],[3,4]], limits = [1,2], k = 2\nOutput: 7\nExplanation:\n\nFrom the second row, we can take at most 2 elements. The elements taken are 4 and 3.\nThe maximum possible sum of at most 2 selected elements is 4 + 3 = 7.\n\n\nExample 2:\n\nInput: grid = [[5,3,7],[8,2,6]], limits = [2,2], k = 3\nOutput: 21\nExplanation:\n\nFrom the first row, we can take at most 2 elements. The element taken is 7.\nFrom the second row, we can take at most 2 elements. The elements taken are 8 and 6.\nThe maximum possible sum of at most 3 selected elements is 7 + 8 + 6 = 21.\n\n\n \nConstraints:\n\nn == grid.length == limits.length\nm == grid[i].length\n1 <= n, m <= 500\n0 <= grid[i][j] <= 10^5\n0 <= limits[i] <= m\n0 <= k <= min(n * m, sum(limits))",
  "llm_response": "import heapq\n\ndef maxSum(grid, limits, k):\n    max_heap = []\n    for i in range(len(grid)):\n        row = sorted(grid[i], reverse=True)\n        for j in range(min(limits[i], len(row))):\n            heapq.heappush(max_heap, -row[j])\n    total = 0\n    count = 0\n    while max_heap and count < k:\n        total += -heapq.heappop(max_heap)\n        count += 1\n    return total",
  "model": "deepseek-chat-v3-0324"
}