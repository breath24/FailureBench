{
  "task_id": "BigCodeBench/590",
  "instruct_prompt": "Extracts the text and href attributes of all anchor tags from a given URL's HTML content, and returns this data in a pandas DataFrame along with the time of data extraction.\nNote that: The function requires internet connectivity to fetch HTML content.\nThe function should raise the exception for: ValueError: If the provided URL is invalid or empty. URLError: If there is an issue with network connectivity or the server.\nThe function should output with:\n    pandas.DataFrame: A DataFrame with columns 'text', 'href', and 'fetch_time'. Each row\n    corresponds to an anchor tag in the HTML, with 'text' and 'href' containing\n    the text and the hyperlink reference of the anchor tag, respectively.\n    'fetch_time' contains the timestamp of when the data was fetched in the format\n    'YYYY-MM-DD HH:MM:SS'.\nYou should write self-contained code starting with:\n```\nimport urllib.request\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\ndef task_func(url):\n```",
  "llm_response": "import urllib.request\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\nfrom urllib.error import URLError\ndef task_func(url):\n    \"\"\"\n    Extracts the text and href attributes of all anchor tags from a given URL's HTML content,\n    and returns this data in a pandas DataFrame along with the time of data extraction.\n    \n    Args:\n        url (str): The URL to fetch HTML content from\n        \n    Returns:\n        pandas.DataFrame: A DataFrame with columns 'text', 'href', and 'fetch_time'\n        \n    Raises:\n        ValueError: If the provided URL is invalid or empty\n        URLError: If there is an issue with network connectivity or the server\n    \"\"\"\n    # Validate URL input\n    if not url or not isinstance(url, str) or url.strip() == \"\":\n        raise ValueError(\"URL cannot be empty or invalid\")\n    \n    url = url.strip()\n    \n    # Basic URL validation\n    if not (url.startswith('http://') or url.startswith('https://')):\n        raise ValueError(\"URL must start with http:// or https://\")\n    \n    try:\n        # Fetch HTML content\n        with urllib.request.urlopen(url) as response:\n            html_content = response.read().decode('utf-8')\n        \n        # Record fetch time\n        fetch_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        \n        # Parse HTML with PyQuery\n        doc = pq(html_content)\n        \n        # Extract anchor tags\n        anchor_data = []\n        for anchor in doc('a').items():\n            text = anchor.text().strip()\n            href = anchor.attr('href') or \"\"\n            anchor_data.append({\n                'text': text,\n                'href': href,\n                'fetch_time': fetch_time\n            })\n        \n        # Create DataFrame\n        df = pd.DataFrame(anchor_data)\n        \n        # Ensure columns exist even if no anchors found\n        if df.empty:\n            df = pd.DataFrame(columns=['text', 'href', 'fetch_time'])\n        \n        return df\n        \n    except urllib.error.URLError as e:\n        raise URLError(f\"Network error or server issue: {e}\")\n    except Exception as e:\n        if \"urlopen error\" in str(e) or \"HTTP Error\" in str(e):\n            raise URLError(f\"Network error or server issue: {e}\")\n        else:\n            raise ValueError(f\"Invalid URL or request: {e}\")",
  "model": "claude-sonnet-4"
}