{
  "task_id": "BigCodeBench/723",
  "instruct_prompt": "Scrape data from a given URL and save the scraped data to a CSV file.\nThe function should output with:\n    CSV_FILE_PATH (str): The path of the CSV file where the scraped data is saved.\nYou should write self-contained code starting with:\n```\nimport urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\n# Constants\nCSV_FILE_PATH = 'scraped_data.csv'\ndef task_func(url):\n```",
  "llm_response": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\nCSV_FILE_PATH = 'scraped_data.csv'\ndef task_func(url):\n    # Fetch the content from the URL\n    response = urllib.request.urlopen(url)\n    web_content = response.read()\n\n    # Parse the content with BeautifulSoup\n    soup = BeautifulSoup(web_content, 'html.parser')\n\n    # Example: Scrape all table rows from the first table on the page\n    # This part should be customized based on the structure of the webpage you are scraping\n    table = soup.find('table')\n    if not table:\n        print(\"No table found on the page.\")\n        return\n\n    rows = table.find_all('tr')\n\n    # Extract headers\n    headers = [header.get_text(strip=True) for header in rows[0].find_all('th')]\n\n    # Extract data\n    data = []\n    for row in rows[1:]:\n        cols = row.find_all('td')\n        data.append([col.get_text(strip=True) for col in cols])\n\n    # Write data to CSV\n    with open(CSV_FILE_PATH, mode='w', newline='', encoding='utf-8') as file:\n        writer = csv.writer(file)\n        if headers:\n            writer.writerow(headers)\n        writer.writerows(data)\n\n    print(f\"Data has been scraped and saved to {CSV_FILE_PATH}\")",
  "model": "gpt-4o"
}