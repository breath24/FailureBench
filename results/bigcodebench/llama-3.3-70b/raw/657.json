{
  "task_id": "BigCodeBench/657",
  "instruct_prompt": "Generate word vectors from a list of texts using the gensim Word2Vec model and nltk.corpus.stopwords. The texts are first cleaned by removing all non-alphanumeric characters except space, lowercased, and stop words are removed.\nThe function should output with:\n    Word2Vec: A trained Word2Vec model.\nYou should write self-contained code starting with:\n```\nimport re\nimport nltk\nfrom gensim.models import Word2Vec\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(texts, stopwords=None):\n```",
  "llm_response": "import re\nimport nltk\nfrom gensim.models import Word2Vec\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(texts, stopwords=None):\n    \"\"\"\n    Generate word vectors from a list of texts using the gensim Word2Vec model.\n\n    Args:\n    texts (list): A list of strings.\n    stopwords (list): A list of stopwords. If None, use nltk.corpus.stopwords.\n\n    Returns:\n    Word2Vec: A trained Word2Vec model.\n    \"\"\"\n    # Download required NLTK data if not already downloaded\n    nltk.download('punkt')\n    nltk.download('stopwords')\n\n    # If stopwords is None, use nltk.corpus.stopwords\n    if stopwords is None:\n        stopwords = set(stopwords.words('english'))\n\n    # Clean the texts by removing all non-alphanumeric characters except space, lowercased, and stop words\n    cleaned_texts = []\n    for text in texts:\n        # Remove all non-alphanumeric characters except space and lowercase\n        cleaned_text = ALPHANUMERIC.sub(' ', text).lower()\n        # Tokenize the text\n        tokens = word_tokenize(cleaned_text)\n        # Remove stop words\n        tokens = [token for token in tokens if token not in stopwords]\n        cleaned_texts.append(tokens)\n\n    # Train the Word2Vec model\n    model = Word2Vec(cleaned_texts, vector_size=100, min_count=1)\n\n    return model",
  "model": "llama-3.3-70b"
}