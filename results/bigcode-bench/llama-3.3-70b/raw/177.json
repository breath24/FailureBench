{
  "task_id": "BigCodeBench/177",
  "instruct_prompt": "Extracts articles whose titles contain specific case-insensitive keywords (\"like\" or \"what\") from a DataFrame and analyzes the frequency of each word in the content of these articles, excluding punctuation.\nThe function should raise the exception for: ValueError: If the DataFrame is empty or does not contain the necessary columns 'Title' and 'Content'.\nThe function should output with:\n    dict: A dictionary with keys as words and values as their corresponding frequency, excluding any punctuation marks.\nYou should write self-contained code starting with:\n```\nimport re\nimport nltk\nfrom string import punctuation\ndef task_func(df):\n```",
  "llm_response": "import re\nimport nltk\nfrom string import punctuation\nimport pandas as pd\ndef task_func(df):\n    \"\"\"\n    Extracts articles whose titles contain specific case-insensitive keywords \n    (\"like\" or \"what\") from a DataFrame and analyzes the frequency of each word \n    in the content of these articles, excluding punctuation.\n\n    Args:\n        df (pd.DataFrame): A DataFrame containing 'Title' and 'Content' columns.\n\n    Returns:\n        dict: A dictionary with keys as words and values as their corresponding frequency.\n\n    Raises:\n        ValueError: If the DataFrame is empty or does not contain the necessary columns 'Title' and 'Content'.\n    \"\"\"\n\n    # Check if the DataFrame is empty\n    if df.empty:\n        raise ValueError(\"The DataFrame is empty\")\n\n    # Check if the DataFrame contains the necessary columns\n    if 'Title' not in df.columns or 'Content' not in df.columns:\n        raise ValueError(\"The DataFrame does not contain the necessary columns 'Title' and 'Content'\")\n\n    # Filter the DataFrame based on the keywords in the title\n    filtered_df = df[df['Title'].str.lower().str.contains('like|what')]\n\n    # Initialize an empty list to store the content of the filtered articles\n    content_list = []\n\n    # Iterate over the rows of the filtered DataFrame\n    for index, row in filtered_df.iterrows():\n        # Remove punctuation from the content and convert to lower case\n        content = re.sub('['+punctuation+']', '', row['Content']).lower()\n        \n        # Tokenize the content into words\n        words = nltk.word_tokenize(content)\n        \n        # Add the words to the content list\n        content_list.extend(words)\n\n    # Use a dictionary to count the frequency of each word\n    word_freq = {}\n    for word in content_list:\n        if word not in word_freq:\n            word_freq[word] = 1\n        else:\n            word_freq[word] += 1\n\n    return word_freq",
  "model": "llama-3.3-70b"
}